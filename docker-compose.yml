version: '3.9'
services:
  vlm-api:
    # Other configuration
    container_name: vlm-api
    build:
      context: ./
      dockerfile: Dockerfile.prod
    env_file: ./.env
    ports:
      - "80:3000"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/_health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"
